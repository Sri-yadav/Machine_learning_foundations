{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebcd9366",
   "metadata": {},
   "source": [
    "# Metric Learning\n",
    "\n",
    "- Many algorithms rely on measuring similarity or distance between data points.\n",
    "- Common similarity metrics:  \n",
    "  - **Euclidean distance** (straight-line distance)  \n",
    "  - **Cosine similarity** (angle-based similarity)\n",
    "- These standard metrics are simple but **not always optimal** for every dataset.\n",
    "- **Metric learning** is the process of learning a better distance measure **tailored to your data**.\n",
    "- This improves performance of algorithms like:  \n",
    "  - k-means clustering  \n",
    "  - k-Nearest Neighbors (kNN) classification\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d697ac9a",
   "metadata": {},
   "source": [
    "\n",
    "## Why Learn a Metric?\n",
    "\n",
    "- Imagine two data points representing images of cats and dogs.\n",
    "- Euclidean distance treats all features equally — but some features might be more important.\n",
    "- Metric learning adjusts the \"importance\" of features automatically.\n",
    "- Result: Similar items are closer; dissimilar items are farther apart in the learned space.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa91ca2",
   "metadata": {},
   "source": [
    "\n",
    "## Recap: Euclidean Distance\n",
    "\n",
    "Between two vectors $x$ and $x'$:\n",
    "\n",
    "$$\n",
    "d(x, x') = \\sqrt{\\sum_{i=1}^D (x_i - x'_i)^2} = \\sqrt{(x - x')^\\top (x - x')}\n",
    "$$\n",
    "\n",
    "- Measures the straight-line distance in $D$ - dimensional space.\n",
    "- Treats each feature dimension equally.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36a18931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance: 3.7416574954986572\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example vectors\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "x_prime = torch.tensor([2.0, 4.0, 6.0])\n",
    "\n",
    "# Euclidean distance\n",
    "def euclidean_distance(a, b):\n",
    "    return torch.norm(a - b, p=2)\n",
    "\n",
    "print(\"Euclidean distance:\", euclidean_distance(x, x_prime).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187391e6",
   "metadata": {},
   "source": [
    "## Parametrizing the Distance Metric with Matrix $A$\n",
    "\n",
    "Modify the distance formula to:\n",
    "\n",
    "$$\n",
    "d_A(x, x') = \\sqrt{(x - x')^\\top A (x - x')}\n",
    "$$\n",
    "\n",
    "- $A$ is a $D \\times D$ matrix controlling feature importance and correlations.\n",
    "- If $A = I$ (identity matrix), this reduces to Euclidean distance.\n",
    "- If $A$ is diagonal with different values, each feature is weighted differently.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ae15fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametrized distance (A=I): 3.7416574954986572\n"
     ]
    }
   ],
   "source": [
    "# Initialize matrix A (D x D), here with requires_grad=True to learn it\n",
    "D = 3\n",
    "A = torch.eye(D, requires_grad=True)  # Start with identity matrix\n",
    "\n",
    "def parametrized_distance(a, b, A):\n",
    "    diff = (a - b).unsqueeze(0)  # shape (1, D)\n",
    "    dist_sq = diff @ A @ diff.t()  # scalar inside a 1x1 tensor\n",
    "    return torch.sqrt(dist_sq.squeeze())\n",
    "\n",
    "print(\"Parametrized distance (A=I):\", parametrized_distance(x, x_prime, A).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d889c0",
   "metadata": {},
   "source": [
    "## Example of Weighted Features\n",
    "\n",
    "Consider $D=3$ and:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "2 & 0 & 0 \\\\\n",
    "0 & 8 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- The second feature dimension contributes the most to the distance.\n",
    "- Features with higher weights have greater influence on similarity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86299ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted distance: 6.557438373565674\n"
     ]
    }
   ],
   "source": [
    "A_weighted = torch.diag(torch.tensor([2.0, 8.0, 1.0]))\n",
    "print(\"Weighted distance:\", parametrized_distance(x, x_prime, A_weighted).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e68b9bd",
   "metadata": {},
   "source": [
    "## What Makes a Valid Metric?\n",
    "\n",
    "A function $d(x, x')$ is a **metric** if it satisfies:\n",
    "\n",
    "1. **Non-negativity:** $d(x, x') \\geq 0$  \n",
    "2. **Triangle inequality:** $d(x, x') \\leq d(x, z) + d(z, x')$ for any $z$  \n",
    "3. **Symmetry:** $d(x, x') = d(x', x)$\n",
    "\n",
    "---\n",
    "\n",
    "## Positive Semidefinite (PSD) Matrix $A$\n",
    "\n",
    "- To satisfy conditions 1 and 2, $A$ must be **positive semidefinite (PSD)**.\n",
    "- Intuition: PSD matrices generalize the idea of nonnegative numbers to matrices.\n",
    "- For any vector $z$:\n",
    "\n",
    "$$\n",
    "z^\\top A z \\geq 0\n",
    "$$\n",
    "\n",
    "- This ensures distances are always nonnegative and the triangle inequality holds.\n",
    "\n",
    "---\n",
    "\n",
    "## Ensuring Symmetry\n",
    "\n",
    "- If the distance formula is not symmetric, we can symmetrize it by:\n",
    "\n",
    "$$\n",
    "d_{sym}(x, x') = \\frac{d_A(x, x') + d_A(x', x)}{2}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Preparing Training Data for Metric Learning\n",
    "\n",
    "- Start with an unlabelled dataset $X = \\{x_i\\}$.\n",
    "- Define two sets of pairs:\n",
    "  - $S$ : pairs $(x_i, x_j)$ that are **similar** (e.g., same class)\n",
    "  - $D$ : pairs $(x_i, x_j)$ that are **dissimilar** (e.g., different classes)\n",
    "- These sets act as **constraints** for learning the metric.\n",
    "\n",
    "---\n",
    "\n",
    "## The Optimization Objective\n",
    "\n",
    "Find $A$ that:\n",
    "\n",
    "- Minimizes distances for similar pairs:\n",
    "\n",
    "$$\n",
    "\\min_A \\sum_{(x_i, x_j) \\in S} d_A(x_i, x_j)^2\n",
    "$$\n",
    "\n",
    "- While keeping distances for dissimilar pairs above a margin $c$ :\n",
    "\n",
    "$$\n",
    "\\text{subject to } \\sum_{(x_i, x_j) \\in D} d_A(x_i, x_j)^2 \\geq c\n",
    "$$\n",
    "\n",
    "- $A$ must remain PSD during optimization.\n",
    "\n",
    "---\n",
    "\n",
    "## How is $A$ Learned?\n",
    "\n",
    "- Use **gradient descent** with projections to ensure $A$ stays PSD.\n",
    "- This involves iteratively updating $A$ to better separate similar and dissimilar pairs.\n",
    "\n",
    "Many advanced methods exist (nonlinear, kernelized metric learning).\n",
    "\n",
    " This linear approach is a solid starting point for practical problems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c708617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.0200\n",
      "Epoch 20: Loss = 0.0015\n",
      "Epoch 40: Loss = 0.0002\n",
      "Epoch 60: Loss = 0.0000\n",
      "Epoch 80: Loss = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Toy dataset with feature vectors (4 points in 3D)\n",
    "X = torch.tensor([\n",
    "    [1., 2., 3.],\n",
    "    [1., 2., 2.9],\n",
    "    [5., 5., 5.],\n",
    "    [5., 5.1, 5.]\n",
    "])\n",
    "\n",
    "# Similar pairs (indices)\n",
    "similar_pairs = [(0,1), (2,3)]\n",
    "# Dissimilar pairs (indices)\n",
    "dissimilar_pairs = [(0,2), (1,3)]\n",
    "\n",
    "# Initialize A as a PSD matrix via A = L^T L\n",
    "L = torch.eye(D, requires_grad=True)  # lower triangular factor\n",
    "\n",
    "optimizer = torch.optim.Adam([L], lr=0.1)\n",
    "margin = 1.0\n",
    "\n",
    "def dist_L(a, b, L):\n",
    "    diff = (a - b).unsqueeze(0)\n",
    "    A = L.t() @ L\n",
    "    dist_sq = diff @ A @ diff.t()\n",
    "    return torch.sqrt(dist_sq.squeeze())\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    A = L.t() @ L\n",
    "\n",
    "    # Loss to pull similar pairs close\n",
    "    loss_sim = torch.stack([dist_L(X[i], X[j], L)**2 for (i,j) in similar_pairs]).sum()\n",
    "    # Loss to push dissimilar pairs apart (hinge loss)\n",
    "    loss_dissim = torch.stack([\n",
    "        torch.relu(margin - dist_L(X[i], X[j], L))**2 for (i,j) in dissimilar_pairs\n",
    "    ]).sum()\n",
    "\n",
    "    loss = loss_sim + loss_dissim\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a206c1",
   "metadata": {},
   "source": [
    "## Intuition Recap\n",
    "\n",
    "- Metric learning **reshapes the space** so that \"similar\" points are closer.\n",
    "- It assigns **importance weights** to features via $A$ .\n",
    "- Learning $A$ is a form of supervised learning guided by similarity/dissimilarity constraints.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8016d",
   "metadata": {},
   "source": [
    "# Learning to Rank\n",
    "\n",
    "A supervised learning technique used to rank documents based on relevance, often applied in search engines.\n",
    "\n",
    "**Goal :**\n",
    "- Learn a function $f$ that outputs scores\n",
    "- These scores induce a ranking similar to human-labeled ranks\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce99bcb",
   "metadata": {},
   "source": [
    "\n",
    "## Training Data Format\n",
    "\n",
    "Each training example $X_i$ contains ranked documents:\n",
    "\n",
    "$$\n",
    "X_i = \\{ (x_{i,j}, y_{i,j}) \\}_{j=1}^{r_i}\n",
    "$$\n",
    "\n",
    "- $x_{i,j}$ : feature vector for doc j\n",
    "- $y_{i,j}$ : rank or score\n",
    "\n",
    "**Feature examples:** Recency, Query match in title, Document length, etc.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b41bbb",
   "metadata": {},
   "source": [
    "\n",
    "## Pointwise Approach\n",
    "\n",
    "- Convert each document to $(x, y)$\n",
    "- Use regression or classification\n",
    "\n",
    " **Limitation:** Ignores document interactions\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cc51bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PyTorch Code: Pointwise Ranking\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RankRegressor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Sample document features and scores\n",
    "X = torch.randn(10, 5)  # 10 docs, 5 features each\n",
    "y = torch.rand(10, 1)   # relevance score\n",
    "\n",
    "model = RankRegressor(input_dim=5)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "output = model(X)\n",
    "loss = loss_fn(output, y)\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b684fd",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Pairwise Approach\n",
    "\n",
    "- Train on pairs: $(x_i, x_k)$\n",
    "- Learn preference: $f(x_i, x_k) \\approx 1$ if $x_i \\succ x_k$\n",
    "\n",
    "Final ranking = Aggregate all pairwise preferences\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d096031",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## PyTorch Code: Pairwise Ranking\n",
    "\n",
    "def pairwise_loss(h_i, h_j):\n",
    "    margin = 1.0\n",
    "    return torch.clamp(margin - (h_i - h_j), min=0).mean()\n",
    "\n",
    "h = model(X).squeeze()\n",
    "pairs = [(0, 1), (2, 3), (4, 5)]  # doc i ranked higher than j\n",
    "\n",
    "loss = sum(pairwise_loss(h[i], h[j]) for i, j in pairs)\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362c3cf",
   "metadata": {},
   "source": [
    "\n",
    "## Listwise Approach\n",
    "\n",
    "- Optimize directly for a ranking metric (e.g., MAP)\n",
    "- **Input:** whole list of docs per query\n",
    "- **Output:** scores that yield best listwise ranking\n",
    "\n",
    " Used in state-of-the-art methods like **LambdaMART**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c1ed15",
   "metadata": {},
   "source": [
    "\n",
    "## MAP (Mean Average Precision)\n",
    "\n",
    "- Measures ranking quality based on relevance\n",
    "\n",
    "$$\n",
    "\\text{AveP}(q) = \\frac{1}{|R|} \\sum_{k=1}^{n} P(k) \\cdot rel(k)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{MAP} = \\frac{1}{Q} \\sum_{q=1}^{Q} \\text{AveP}(q)\n",
    "$$\n",
    "\n",
    "- $P(k)$ : Precision at top-k\n",
    "- $rel(k)$: 1 if relevant at rank k, 0 otherwise\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bfb674",
   "metadata": {},
   "source": [
    "\n",
    "## LambdaMART (Gradient Boosted Ranking)\n",
    "\n",
    "- Uses trees to model ranking function \\( h(x) \\)\n",
    "- Pairwise function:\n",
    "\n",
    "$$\n",
    "f(x_i, x_k) = \\frac{1}{1 + \\exp((h(x_k) - h(x_i)) \\cdot \\sigma)}\n",
    "$$\n",
    "\n",
    "- **Loss:** Cross-entropy on these pairwise comparisons\n",
    "- Gradient is modified to directly optimize MAP\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b44f04",
   "metadata": {},
   "source": [
    "\n",
    "## LambdaMART Key Idea\n",
    "\n",
    "- Replace true gradient with a metric-aware gradient\n",
    "\n",
    "- Boosting adds trees to reduce metric error\n",
    "- Direct optimization of MAP, not just cost function\n",
    "\n",
    "- One of the few methods optimizing *what we actually care about*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffd6e5b",
   "metadata": {},
   "source": [
    "\n",
    "## Sorting from Pairwise Scores\n",
    "\n",
    "To convert pairwise predictions into a ranking:\n",
    "- Use any sorting algorithm (e.g. Bubble Sort)\n",
    "- Replace numeric comparison with $f(x_i, x_j)$\n",
    "\n",
    "```python\n",
    "def compare_docs(i, j):\n",
    "    return f[i][j] > 0.5  # f(i ranked higher than j)\n",
    "\n",
    "ranking = sorted(range(len(docs)), key=lambda i: scores[i], reverse=True)\n",
    "```\n",
    "\n",
    "You can use `scikit-learn`, `XGBoost`, or `LightGBM` for LambdaMART implementations.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665634b8",
   "metadata": {},
   "source": [
    "\n",
    "# Learning to Recommend\n",
    "\n",
    "- Learning to Recommend builds **recommender systems**.\n",
    "- **Goal:** Suggest content (e.g., movies, books) to users based on their past behavior.\n",
    "\n",
    "Two classic methods:\n",
    "- **Content-based filtering**\n",
    "- **Collaborative filtering**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72705815",
   "metadata": {},
   "source": [
    "\n",
    "## Content-Based Filtering\n",
    "\n",
    "- Learns user preferences from features of the content they consumed.\n",
    "- Example features: topic, author, price, recency.\n",
    "\n",
    "```python\n",
    "# Content-based example using scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = ...  # Feature vectors (e.g., TF-IDF vectors of articles)\n",
    "y = ...  # Labels (1 if user read the article, 0 otherwise)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e408af",
   "metadata": {},
   "source": [
    "\n",
    "## Problems with Content-Based Filtering\n",
    "\n",
    "- Users get trapped in a **filter bubble**.\n",
    "- Recommendations lack diversity.\n",
    "- Recommends things user may already know.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dadcaf3",
   "metadata": {},
   "source": [
    "\n",
    "## Collaborative Filtering\n",
    "\n",
    "- Based on user-item interactions\n",
    "- Uses other users' preferences to recommend new items.\n",
    "\n",
    "**Data structure:** sparse **user-item matrix**.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Sparse user-item matrix (5 users x 6 items)\n",
    "ratings = np.array([\n",
    "    [5, 0, 0, 1, 0, 0],\n",
    "    [4, 0, 0, 1, 0, 0],\n",
    "    [1, 1, 0, 5, 0, 0],\n",
    "    [1, 0, 0, 4, 0, 0],\n",
    "    [0, 1, 5, 4, 0, 0],])\n",
    "\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991c7ba",
   "metadata": {},
   "source": [
    "\n",
    "## Two algorithms to do it : -\n",
    "\n",
    "## Factorization Machines (FM)\n",
    "\n",
    "- Designed for sparse data.\n",
    "- Models feature interactions without exploding parameter size.\n",
    "\n",
    "FM Model:\n",
    "$$\n",
    "f(x) = b + \\sum w_i x_i + \\sum_{i=1}^{D} \\sum_{j=i+1}^{D} \\langle v_i, v_j \\rangle x_i x_j\n",
    "$$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a98d2",
   "metadata": {},
   "source": [
    "\n",
    "### FM in PyTorch (Basic Idea)\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FactorizationMachine(nn.Module):\n",
    "    def __init__(self, n_features, k):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(n_features, 1)\n",
    "        self.v = nn.Parameter(torch.randn(n_features, k))\n",
    "\n",
    "    def forward(self, x):\n",
    "        linear_term = self.linear(x)\n",
    "        interactions = 0.5 * torch.sum(\n",
    "            (x @ self.v) ** 2 - (x ** 2) @ (self.v ** 2), dim=1, keepdim=True)\n",
    "        return linear_term + interactions\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d0d56b",
   "metadata": {},
   "source": [
    "\n",
    "### Loss Function for FM\n",
    "\n",
    "- For binary classification:\n",
    "$$\n",
    "\\text{loss}(f(x), y) = \\log(1 + e^{-yf(x)}) / \\log(2)\n",
    "$$\n",
    "- Optimized via stochastic gradient descent.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b0ff8f",
   "metadata": {},
   "source": [
    "\n",
    "## Denoising Autoencoders (DAE)\n",
    "\n",
    "- Input = user’s past behavior (with random corruption)\n",
    "- Output = reconstruct full user behavior\n",
    "- Ideal for recommendation via **input reconstruction**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10b1de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DAE in PyTorch\n",
    "\n",
    "class DAE(nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(n_inputs, 128)\n",
    "        self.decoder = nn.Linear(128, n_inputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.relu(self.encoder(x))\n",
    "        return torch.sigmoid(self.decoder(h))\n",
    "\n",
    "# Simulate input corruption\n",
    "x = torch.FloatTensor([[1, 0, 0, 1, 1]])\n",
    "x_corrupt = x.clone()\n",
    "x_corrupt[0,1] = 0\n",
    "model = DAE(n_inputs=5)\n",
    "pred = model(x_corrupt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34884a45",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Recommend from DAE Output\n",
    "\n",
    "```python\n",
    "# Recommend items with highest scores in pred not already seen in x\n",
    "scores = pred.detach().numpy().flatten()\n",
    "recommend_idx = [i for i in np.argsort(-scores) if x[0,i] == 0]\n",
    "print(\"Recommend item indices:\", recommend_idx[:3])\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9738df",
   "metadata": {},
   "source": [
    "\n",
    "## Feed-Forward Neural Network for Recommendation\n",
    "\n",
    "- Input: (user one-hot, item one-hot)\n",
    "- Output: rating prediction\n",
    "\n",
    "```python\n",
    "class RecNN(nn.Module):\n",
    "    def __init__(self, n_users, n_items):\n",
    "        super().__init__()\n",
    "        self.user_embed = nn.Embedding(n_users, 32)\n",
    "        self.item_embed = nn.Embedding(n_items, 32)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64, 128), nn.ReLU(), nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user_id, item_id):\n",
    "        u = self.user_embed(user_id)\n",
    "        i = self.item_embed(item_id)\n",
    "        x = torch.cat([u, i], dim=1)\n",
    "        return self.fc(x)\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74329609",
   "metadata": {},
   "source": [
    "\n",
    "# Self-Supervised Learning :\n",
    "## Word Embeddings\n",
    "\n",
    "- Word embeddings are **vector representations** of words.\n",
    "- They capture **semantic meaning**: similar words ≈ similar vectors.\n",
    "- Trained in a self-supervised way: the model learns from **unlabeled data**.\n",
    "- One popular method: **Word2Vec (Skip-Gram)**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda357c",
   "metadata": {},
   "source": [
    "\n",
    "## Skip-Gram Intuition\n",
    "\n",
    "- **Goal:** predict **context words** from a **center word**.\n",
    "- Example (window=2):  \n",
    "  **Sentence:** *\"I love learning machine learning\"*  \n",
    "  **Skip-gram pairs:**  \n",
    "  - ('love', 'I'), ('love', 'learning')  \n",
    "  - ('learning', 'love'), ('learning', 'machine')\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126587eb",
   "metadata": {},
   "source": [
    "\n",
    "##  Skip-Gram Code with PyTorch (Toy Example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d67fd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.8702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 0.8057\n",
      "Epoch 200, Loss: 0.7957\n",
      "Epoch 300, Loss: 0.7938\n",
      "Epoch 400, Loss: 0.7932\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Sample toy corpus\n",
    "corpus = \"I love machine learning and I love deep learning\"\n",
    "\n",
    "# Preprocessing\n",
    "words = corpus.lower().split()\n",
    "vocab = list(set(words))\n",
    "word2idx = {w: idx for idx, w in enumerate(vocab)}\n",
    "idx2word = {idx: w for w, idx in word2idx.items()}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Create Skip-gram pairs (window=1)\n",
    "def create_skipgrams(words, window_size=1):\n",
    "    pairs = []\n",
    "    for i in range(window_size, len(words) - window_size):\n",
    "        target = words[i]\n",
    "        context = [words[i - j] for j in range(1, window_size + 1)]\n",
    "        context += [words[i + j] for j in range(1, window_size + 1)]\n",
    "        for ctx_word in context:\n",
    "            pairs.append((target, ctx_word))\n",
    "    return pairs\n",
    "\n",
    "pairs = create_skipgrams(words)\n",
    "\n",
    "# Convert to indices\n",
    "X_train = torch.tensor([word2idx[p[0]] for p in pairs])\n",
    "Y_train = torch.tensor([word2idx[p[1]] for p in pairs])\n",
    "\n",
    "# Model\n",
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.output = nn.Linear(embed_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        out = self.output(emb)\n",
    "        return out\n",
    "\n",
    "model = Word2Vec(vocab_size, embed_dim=10)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = loss_fn(output, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0094419d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#  Visualizing Word Embeddings (after training)\n",
    "\n",
    "# Get embeddings\n",
    "embeddings = model.embedding.weight.data.detach().numpy()\n",
    "\n",
    "# Reduce to 2D for plotting\n",
    "n_samples = embeddings.shape[0]\n",
    "adjusted_perplexity = min(30, n_samples - 1)  # or even n_samples // 3\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=adjusted_perplexity, random_state=42)\n",
    "reduced = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, label in enumerate(vocab):\n",
    "    x, y = reduced[i]\n",
    "    plt.scatter(x, y)\n",
    "    plt.text(x + 0.01, y + 0.01, label)\n",
    "plt.title(\"2D Visualization of Word Embeddings\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d405d072",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
