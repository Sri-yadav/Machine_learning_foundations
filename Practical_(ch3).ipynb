{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c006bf9",
   "metadata": {},
   "source": [
    "Using all those five learning models which we discussed earlier for predicting.\n",
    "\n",
    "**Using buit-in Iris dataset from Scikit-learn**\n",
    "\n",
    "- This dataset contains 150 samples of iris flowers.\n",
    "\n",
    "- Each sample has 4 features:\n",
    "    - Sepal length (cm)\n",
    "    - Sepal width (cm)\n",
    "    - Petal length (cm)\n",
    "    - Petal width (cm)\n",
    "\n",
    "- Each sample belongs to one of 3 species:\n",
    "    - Setosa (label = 0)\n",
    "    - Versicolor (label = 1)\n",
    "    - Virginica (label = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3f1ef574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "print(df.head()) # View dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bccb3a",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "47d3bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and labels\n",
    "X = df.drop('target', axis=1)  # Feature data\n",
    "y = df['target']               # Labels\n",
    "\n",
    "# Split into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data (80% for training, 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8972e2d6",
   "metadata": {},
   "source": [
    "# Code to Train and Predict\n",
    "\n",
    "## 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ef0f4ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Create the model\n",
    "LR_model = LinearRegression()\n",
    "\n",
    "# Train the model on training data\n",
    "LR_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_pred_lin = LR_model.predict(X_test)\n",
    "\n",
    "# Since it's output is continuous numbers, we round them to nearest class\n",
    "y_pred_round = np.round(y_pred_lin).astype(int)\n",
    "\n",
    "# Clip the predictions to stay within valid label range [0, 2]\n",
    "y_pred_clipped = np.clip(y_pred_round, 0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee13d3",
   "metadata": {},
   "source": [
    "### Accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "63cc9015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Linear-Regression : 0.9333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.89      0.89      0.89         9\n",
      "   virginica       0.89      0.89      0.89         9\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_lin = accuracy_score(y_test, y_pred_clipped)\n",
    "print(\"Accuracy of Linear-Regression :\", acc_lin)\n",
    "\n",
    "# See a per-class breakdown\n",
    "print(classification_report(y_test, y_pred_clipped, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1fe29b",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Accuracy: 93.3%\n",
    "Predicted labels: Mostly correct, but not perfect\n",
    "Evaluation: Misclassifies some versicolor/virginica samples.\n",
    "\n",
    "It is not meant for classification but for continuous values. We are rounding these values to nearest classes.\n",
    "That's why : \n",
    "- It is working for classes that are well seperated numerically (Setosa).\n",
    "- Stuggles when class boundaries arent linear. (btw versicolor and virginica)\n",
    "\n",
    "**Shouldn't be used for classification. Worked here only because the the probelm is simple and setosa is well seperated.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7bdcab",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b7b51535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create the model\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=200,      # allow enough iterations to converge\n",
    ")\n",
    "\n",
    "# Train (fit) on the training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_pred_log = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "16e17a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic-Regression : 0.9666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       1.00      0.89      0.94         9\n",
      "   virginica       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "acc_log = accuracy_score(y_test, y_pred_log)\n",
    "print(\"Accuracy of Logistic-Regression :\", acc_log)\n",
    "\n",
    "# See a per-class breakdown\n",
    "print(classification_report(y_test, y_pred_log, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86266d4",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Accuracy: 96.7%\n",
    "Slighly low recall for Virgenica\n",
    "\n",
    "**Why this performance?**\n",
    "Logistic regression draws linear boundaries between classes.\n",
    "\n",
    "Works very well when classes are linearly separable — and Iris almost is (except versicolor vs virginica overlap).\n",
    "\n",
    "What this tells about the data?\n",
    "The dataset is mostly linearly separable, except a few cases between versicolor and virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130856b",
   "metadata": {},
   "source": [
    "## 3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "938b4bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create the model\n",
    "dec_tree = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",   # or \"entropy\"\n",
    "    max_depth=3,              # prevent overfitting\n",
    "    min_samples_split=4,      # don’t split unless ≥4 samples\n",
    "    min_samples_leaf=2,       # each leaf should have ≥2 samples\n",
    "    random_state=30     # reproducible splits\n",
    ")\n",
    "\n",
    "# Fit (train) on the training data\n",
    "dec_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_pred_dt = dec_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eed01c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision-Tree: 0.9333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.89      0.89      0.89         9\n",
      "   virginica       0.89      0.89      0.89         9\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Accuracy of Decision-Tree:\", acc_dt)\n",
    "print(classification_report(y_test, y_pred_dt, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a397ea6b",
   "metadata": {},
   "source": [
    "### Evaluation of this model\n",
    "\n",
    "Accuracy: 93.3%\n",
    "\n",
    "Why this performance?\n",
    "Trees split based on thresholds of feature values (like petal length < x).\n",
    "In Iris, a few splits are enough to classify most points correctly — but they may still make errors on overlapping samples.\n",
    "\n",
    "**What it says about the data:**\n",
    "\n",
    "Decision boundaries based on specific feature thresholds are enough to distinguish most classes.\n",
    "But the noise/overlap between class 1 and 2 causes misclassifications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f56105e",
   "metadata": {},
   "source": [
    "## 4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "566bc839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create the model\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=30)\n",
    "\n",
    "# Train the model\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "280140b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM : 0.9666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       1.00      0.89      0.94         9\n",
      "   virginica       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Accuracy of SVM :\", acc_svm)\n",
    "print(classification_report(y_test, y_pred_svm, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352abbaa",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Accuracy: 96.7% - same as logistic regression\n",
    "\n",
    "Same interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb38f577",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "00f06e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create the model\n",
    "k_nn = KNeighborsClassifier(n_neighbors=5)  # 5 nearest neighbors\n",
    "\n",
    "# Train the model (just memorizes training data)\n",
    "k_nn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_k_nn = k_nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "776c66e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of k-Nearest Neighbors : 0.9333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       1.00      0.78      0.88         9\n",
      "   virginica       0.82      1.00      0.90         9\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.94      0.93      0.92        30\n",
      "weighted avg       0.95      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "acc_k_nn = accuracy_score(y_test, y_pred_k_nn)\n",
    "print(\"Accuracy of k-Nearest Neighbors :\", acc_k_nn)\n",
    "print(classification_report(y_test, y_pred_k_nn, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3afdd2",
   "metadata": {},
   "source": [
    "Accuracy: 93.3%\n",
    "\n",
    "What this tells about the data:\n",
    "\n",
    "Local neighborhood for Setosa is clean → perfect accuracy\n",
    "\n",
    "But Versicolor vs Virginica overlap in feature space → confusion in neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d5bcd",
   "metadata": {},
   "source": [
    "# Regression Problem\n",
    "\n",
    "Similar to the previous one, but here we are trying to solve a regression problem instead of classification.\n",
    "\n",
    "We are using another built-in real world regression dataset - California_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "99a2c6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model   MSE  R² Score\n",
      "0  Linear Regression  0.56      0.58\n",
      "1      Decision Tree  0.50      0.62\n",
      "2      KNN Regressor  0.43      0.67\n",
      "3   SVR (RBF Kernel)  0.36      0.73\n"
     ]
    }
   ],
   "source": [
    "# Combined code for training four algorithms\n",
    " \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "\n",
    "# Optional: Standardize features (important for SVR, KNN, etc.)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=30),\n",
    "    \"KNN Regressor\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"SVR (RBF Kernel)\": SVR(kernel='rbf')\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"MSE\": round(mse, 2),\n",
    "        \"R² Score\": round(r2, 2)\n",
    "    })\n",
    "\n",
    "# Show results\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6cc518",
   "metadata": {},
   "source": [
    "# Evaluation : -\n",
    "\n",
    "1. SVR (RBF Kernel) – Best MSE = 0.36\n",
    "\n",
    "- Most accurate model overall.\n",
    "\n",
    "- This low MSE means the model is consistently close to the true values.\n",
    "\n",
    "- The RBF kernel captures nonlinear relationships smoothly.\n",
    "\n",
    "- Great when the data has complex, curved, or indirect patterns.\n",
    "\n",
    "\n",
    "**The data likely has nonlinear dependencies.**\n",
    "\n",
    "2. KNN Regressor – MSE = 0.43\n",
    "\n",
    "- Second-best performance and very close to SVR.\n",
    "\n",
    "- Predicts values based on averages of nearby training samples.\n",
    "\n",
    "**The dataset has some local structure or clusters where nearby samples tend to have similar outputs.**\n",
    "\n",
    "3. Decision Tree – MSE = 0.50\n",
    "\n",
    "- Less precise than KNN or SVR.\n",
    "\n",
    "- Predicts using stepwise thresholds, which might miss finer variations.\n",
    "\n",
    "- Can create jumps in predictions instead of smooth transitions.\n",
    "\n",
    "**The data has some natural thresholds or decision points. Not good but atleast better than Linear Regression**\n",
    "\n",
    "4. Linear Regression – MSE = 0.56\n",
    "\n",
    "- Worst performer here.\n",
    "\n",
    "- Assumes a straight-line relationship between inputs and target.\n",
    "\n",
    "- MSE is higher because it cannot handle curved or complex patterns.\n",
    "\n",
    "- Still not terrible — means some linear trend is present, just not enough.\n",
    "\n",
    "\n",
    "**The model is too simple for this dataset — linear assumptions don't capture the full pattern.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
