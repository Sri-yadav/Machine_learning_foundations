{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7ab3f4",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "### [Background]\n",
    "\n",
    "#### Problem : Detecting Spam Emails\n",
    "(Deciding whether or not a given email is spam or not_spam)\n",
    "\n",
    "If we were to use : **Traditional Programming**, then we'll have to \n",
    "\n",
    "- write explicit rules for recognizing every possible spam message\n",
    "\n",
    "- Eg. If the message contains - *\"win money\", \"free offer\"*, etc then label it as Spam. Else not_spam.\n",
    "\n",
    "**Issues**\n",
    "- not feasiable if the rules are too many or complex, easy to bypass (eg. using - \"freee\" instead of \"free\"), no learning, poor generalization\n",
    "\n",
    "---\n",
    "\n",
    "# Machine Learning  \n",
    "(A better solution)\n",
    "\n",
    "Machine learning is a subfield of **artificial intelligence** that focuses on **learning from the data** itself by **recognizing pattern**s in it and making decisions based on the learned patterns **without being explicitly programmed**.\n",
    "\n",
    "---\n",
    "\n",
    "## What is needed (to make a machine learn)?\n",
    "1. **Dataset** (a collection of examples or instances of the given problem)\n",
    "2. **Algorithm** (step by step procedure or a set of rules)\n",
    "\n",
    "### What the machine does? \n",
    "Uses the **algorithm** to make a **model** based on the given dataset. Then uses the model to predict and solve a problem.\n",
    "\n",
    "---\n",
    "\n",
    "# Types of Machine Learning\n",
    "\n",
    "(based on the availability and nature of the data)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Supervised Learning\n",
    "\n",
    "Here, **Dataset** - is a collection of labeled examples {(x<sub>i</sub>,y<sub>i</sub> )}<sup>N</sup><sub>i=1</sub>\n",
    "\n",
    "where, **x<sub>i</sub>** - **feature vector** \n",
    "For eg.,\n",
    "$$\n",
    "x_i=[x^{(1)}, x^{(2)}, x^{(3)},....x^{(D)}]\n",
    "$$\n",
    "where $x^{(1)}, x^{(2)}, x^{(3)},...$ can be features like - frequency of particular words, length of the email, presence of special characters, etc. for spam or not_spam problem.\n",
    "\n",
    "**y<sub>i</sub>** - **label** (can be anything like a class (spam or not_spam) or a real number (probability of a email being spam or not_spam))\n",
    "\n",
    "\n",
    "**Goal :** Produce a model that takes a feature vector as input and output the label for it.\n",
    "\n",
    "---\n",
    "\n",
    "#### Support Vector Machine (SVM) \n",
    "\n",
    "- a supervised learning algorithm\n",
    "\n",
    "- Where : labels - classes\n",
    "- Originally a binary classification problem but can be extended to multiclass.\n",
    "- requires positive examples (class of interest) - labelled as +1  & negative examples (the other class) - labelled as -1 \n",
    "\n",
    "- creates a decision boundary (a hyperplane) to seperate the two categories of data\n",
    "\n",
    "-  prefer that the hyperplane separates positive examples from negative ones with the **largest margin** (Margin: is the distance between the decision boundary and the points of the class that are nearest to it).\n",
    "- Why largest Margin? (for better generalization and making the model more roboust to noise).\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"Images/SVM.png\" width= 500> <img src=\"Images/svm_b_2.png\" width= 500>\n",
    "<img src=\"Images/svm_a_1.png\" width= 500> <img src=\"Images/svm_d_1.png\" width= 500>\n",
    "\n",
    "---\n",
    "\n",
    "- **Decision boundary** (the hyperplane)  given by,\n",
    "    $$\n",
    "    \\mathbf{wx} - b = 0\n",
    "    $$\n",
    "    where $\\mathbf{w}$ - a weight vector, $\\mathbf{x}$ - feature vector, b - bias\n",
    "            \n",
    "- A label is given by,\n",
    "    $$\n",
    "    y = sign(\\mathbf{wx}-b)\n",
    "    $$\n",
    "\n",
    "- **Model** defined as,\n",
    "    $$\n",
    "    f(x) = sign(\\mathbf{w^*x}-b^*)\n",
    "    $$\n",
    "    where, $\\mathbf{w^*}$ - optimised value of $\\mathbf{w}$, $b^*$ - optimised value of b\n",
    "\n",
    "- Constrains : $y_i (\\mathbf{wx} - b) \\ge 1$ (Why? Explained later...)\n",
    "- Minimize $||\\mathbf{w}||$ (so that the margin is large)\n",
    "- Eg. , checking if a message is spam or not_spam.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Unsupervised Learning\n",
    "\n",
    "Here, the **Dataset** - is a collection of unlabelled examples {x<sub>i</sub>}<sup>N</sup><sub>i=1</sub>\n",
    "\n",
    "where **x<sub>i</sub>** - feature vector\n",
    "\n",
    "**Goal :** Create a model that takes an input vector and returns something that give information about the structure/pattern of the data. \n",
    "**Eg -** grouping of mails into different categories without spam and not spam labels.\n",
    "\n",
    "---\n",
    "# 3. Semi-Supervised Learning\n",
    "\n",
    "Here, the **Dataset** - collection of both labelled and unlabeled data\n",
    "\n",
    "**Goal:** Same as Supervised learning. The unlabelled data is used to improve the model's understanding of the structure of the data distribution.\n",
    "**Eg -** a combination of both - emails with spam and not_spam labels & without labels.\n",
    "\n",
    "This type of learning is important as most of our data is unlabelled.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Reinforcement Learning\n",
    "\n",
    "Here the **Dataset :** has No fixed data, the **agent** (machine) makes its own dataset.\n",
    "\n",
    "Few terms:- \n",
    "- **Environment $(E)$**: The external system the agent interacts with.\n",
    "- **State $(S)$**: A specific situation or configuration of the environment.\n",
    "- **Action $(A)$**: A move or decision the agent can make in a given state.\n",
    "- **Reward $(R)$**: Feedback signal indicating the value of an action taken.\n",
    "- **Optimal actions**: The best actions that maximize long-term rewards.\n",
    "\n",
    "In this the machine lives in an **environment $(E)$** , precieves the **state$(S)$** of the environment and takes **action $(A)$** in every states. The different actions taken leads to different **rewards $(R)$**. Over time it learns what are the **optimal actions** in a particular state. \n",
    "\n",
    "$$\n",
    "E=(S,A,P,R,Î³) \\text{ }\n",
    "$$\n",
    "where **E -** Environment, **A -** action, **P-** transition function,\n",
    "**R -** rewards, **$\\boldsymbol{\\gamma}$** - reward factor\n",
    "\n",
    "---\n",
    "\n",
    "**Eg.** Solving a maze problem, \n",
    "<img src=\"Images/Maze_1.png\" width = 500>  \n",
    "\n",
    "**Goal :** To learn a **Policy** (a function that takes feature vector of a state as input and give the optimal action that can be taken in that state as output).\n",
    "\n",
    "---\n",
    "\n",
    "# Why the Model Work on New Data?\n",
    "\n",
    "Because of **statistical generalizations**: \n",
    "\n",
    "- If the data is random and representative then we can make statements or predictions about the whole population or future data.\n",
    "\n",
    "**PAC learning theory** explores this in more detail (but due to the limitations (assumptions it make) we don't use it now a days). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
