{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7ab3f4",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "### [Background]\n",
    "\n",
    "#### Problem : Detecting Spam Emails\n",
    "\n",
    "**Traditional Programming**\n",
    "\n",
    "- writing explicit rules for recognizing every possible spam message\n",
    "\n",
    "- Eg. If the message contains - *\"win money\", \"free offer\"*, etc.\n",
    "\n",
    "**Issues**\n",
    "- not feasiable if too many and complex rules, easy to bypass, no learning, poor generalization\n",
    "---\n",
    "\n",
    "# Machine Learning  \n",
    "\n",
    "Machine learning is a subfield of **artificial intelligence** that focuses on developing **algorithms** that enable systems to **learn patterns** and make decisions from data **without being explicitly programmed**.\n",
    "\n",
    "---\n",
    "\n",
    "## What is needed ?\n",
    "1. **Dataset** \n",
    "2. **Algorithm**\n",
    "\n",
    "### What the machine does? \n",
    "Uses the **algorithm** to make a **model** based on the given dataset. Then uses the model to predict and solve a problem.\n",
    "\n",
    "---\n",
    "\n",
    "# Types of Machine Learning\n",
    "\n",
    "$$\n",
    "\\text{(based on the availability and nature of the data)}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Supervised Learning\n",
    "\n",
    "**Dataset** - collection of labeled examples {(x<sub>i</sub>,y<sub>i</sub> )}<sup>N</sup><sub>i=1</sub>\n",
    "\n",
    "**x<sub>i</sub>** - **feature vector** \n",
    "$$\n",
    "x_i=[x^{(1)}, x^{(2)}, x^{(3)},....x^{(D)}]\n",
    "$$\n",
    "\n",
    "**y<sub>i</sub>** - **label**\n",
    "\n",
    "**Goal :** Produce a model that takes a feature vector as input and output the label for it.\n",
    "\n",
    "---\n",
    "\n",
    "#### Support Vector Machine (SVM) \n",
    "\n",
    "- a supervised learning algorithm\n",
    "\n",
    "- labels - classes\n",
    "\n",
    "- requires positive examples - labelled as +1 (class of interest) & negative examples - labelled as -1 (the other class)\n",
    "\n",
    "- creates a decision boundary to seperate the two categories of data\n",
    "\n",
    "-  prefer that the hyperplane separates positive examples from negative ones with the **largest margin** (for better generalization and making the model more roboust to noise).\n",
    "\n",
    "---\n",
    "![](Images/SVM.png) ![](Images/svm_b_2.png)\n",
    "![](Images/svm_a_1.png) ![](Images/svm_d_1.png)\n",
    "\n",
    "---\n",
    "\n",
    "- **Decision boundary** (the hyperplane)  given by,\n",
    "$$\n",
    "\\mathbf{wx} - b = 0\n",
    "$$\n",
    "            \n",
    "- A label, $y = sign(\\mathbf{wx}-b)$\n",
    "\n",
    "- **Model:** $f(x) = sign(\\mathbf{w^*x}-b^*)$\n",
    "    \n",
    "    $w^*$ - optimised value of w\n",
    "    $b^*$ - optimised value of b\n",
    "\n",
    "- Constrains : $y_i (\\mathbf{wx} - b) \\ge 1$\n",
    "- Minimize $||\\mathbf{w}||$ (so that the margin is large)\n",
    "- Eg. , checking if a message is spam or not_spam.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Unsupervised Learning\n",
    "\n",
    "**Dataset** - collection of unlabelled examples {x<sub>i</sub>}<sup>N</sup><sub>i=1</sub>\n",
    "\n",
    "**x<sub>i</sub>** - feature vector\n",
    "\n",
    "**Goal :** Create a model that takes an input vector and returns something that give information about the structure/pattern of the data. \n",
    "**Eg -** emails without spam and not spam labels, recommendations of videos and songs.\n",
    "\n",
    "---\n",
    "# 3. Semi-Supervised Learning\n",
    "\n",
    "**Dataset** - collection of both labelled and unlabeled data\n",
    "\n",
    "**Goal:** Same as Supervised learning. The unlabelled data is used to improve the model's understanding of the structure of the data distribution.\n",
    "**Eg -** a combination of both - emails with spam and not_spam labels & without labels (most of our data is unlabeled).\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Reinforcement Learning\n",
    "\n",
    "**Dataset :** No fixed data, the **agent** makes its own dataset.\n",
    "\n",
    "In this the machine lives in an **environment $(E)$** , precieves the **state$(S)$** of the environment and takes **action $(A)$** in every states. The different actions taken leads to different **rewards $(R)$**. Over time it learns what are the **optimal actions** in a particular state. \n",
    "\n",
    "$$\n",
    "E=(S,A,P,R,Î³) \\text{ }\n",
    "$$\n",
    "where **E -** Environment, **A -** action, **P-** transition function,\n",
    "**R -** rewards, **$\\boldsymbol{\\gamma}$** - reward factor\n",
    "\n",
    "---\n",
    "\n",
    "**Eg.** Solving a maze problem,  \n",
    "![](/Images/Maze_1.png) \n",
    "\n",
    "**Goal :** To learn a **Policy** (a function that takes feature vector of a state as input and give the optimal action that can be taken in that state as output).\n",
    "\n",
    "---\n",
    "\n",
    "# Why the Model Work on New Data?\n",
    "\n",
    "Because of **statistical generalizations**: \n",
    "\n",
    "- If the data is random and representative then we can make statements or predictions about the whole population or future data.\n",
    "\n",
    "**PAC learning theory** explores this in more detail (but due to the limitations (assumptions it make) we don't use it now a days). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e808a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
